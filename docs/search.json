[
  {
    "objectID": "pages/slt/svm/index.html#what-is-svm-the-widest-street-algorithm",
    "href": "pages/slt/svm/index.html#what-is-svm-the-widest-street-algorithm",
    "title": "üéì Support Vector Machines (SVM) and Linear Algebra",
    "section": "üéØ What is SVM? (The ‚ÄúWidest Street‚Äù Algorithm)",
    "text": "üéØ What is SVM? (The ‚ÄúWidest Street‚Äù Algorithm)\nWhile Logistic Regression focuses on probability, SVM focuses on geometry. Its goal is not just to separate two classes, but to separate them with the widest possible gap.\n\nAnalogy: The Demilitarized Zone (DMZ)\nImagine two warring countries (Class A and Class B). A peace treaty requires a border between them. * Bad Border (Logistic Regression might pick this): A line that runs right next to a Class A village. It‚Äôs technically correct, but risky. * SVM Border: SVM looks for the ‚Äúwidest possible river‚Äù or DMZ that can fit between the closest villages of both countries. The center of this river is the decision boundary. * Support Vectors: These are the specific villages (data points) located right on the edge of the river. They ‚Äúsupport‚Äù or define the boundary. If you move the other villages, the border doesn‚Äôt change. If you move the Support Vectors, the border moves.",
    "crumbs": [
      "Home",
      "SVM & LA"
    ]
  },
  {
    "objectID": "pages/slt/svm/index.html#the-linear-algebra-perspective-data-as-vectors",
    "href": "pages/slt/svm/index.html#the-linear-algebra-perspective-data-as-vectors",
    "title": "üéì Support Vector Machines (SVM) and Linear Algebra",
    "section": "üèóÔ∏è 1. The Linear Algebra Perspective: Data as Vectors",
    "text": "üèóÔ∏è 1. The Linear Algebra Perspective: Data as Vectors\nIn SVM, Linear Algebra is not just a container; it is the logic of the entire algorithm.\n\nA. Data Representation (Vectors and Matrices)\nEvery data point is a vector in space. * The Input (\\(x\\)): A vector pointing from the origin \\((0,0)\\) to the data point‚Äôs location. * The ‚ÄúStreet‚Äù Normal (\\(w\\)): A vector that is perpendicular (at 90 degrees) to the boundary line. It dictates the orientation of the street. * The ‚ÄúStreet‚Äù Position (\\(b\\)): A scalar that dictates the position of the street relative to the origin.\n\n\nB. The Geometric Interpretation (The Hyperplane)\nThe decision boundary is defined by the Linear Algebra equation of a hyperplane:\n\\[w \\cdot x + b = 0\\]\n\n\\(w \\cdot x\\) (The Dot Product): This is the projection of the data point \\(x\\) onto the direction \\(w\\). It measures ‚Äúhow far‚Äù the point is in the direction of the street‚Äôs orientation.\nThe Decision:\n\nIf \\(w \\cdot x + b &gt; 0\\), the point is on the ‚ÄúPositive‚Äù side.\nIf \\(w \\cdot x + b &lt; 0\\), the point is on the ‚ÄúNegative‚Äù side.",
    "crumbs": [
      "Home",
      "SVM & LA"
    ]
  },
  {
    "objectID": "pages/slt/svm/index.html#linear-transformations-the-kernel-trick",
    "href": "pages/slt/svm/index.html#linear-transformations-the-kernel-trick",
    "title": "üéì Support Vector Machines (SVM) and Linear Algebra",
    "section": "üîÆ 2. Linear Transformations: The Kernel Trick",
    "text": "üîÆ 2. Linear Transformations: The Kernel Trick\nThis is where SVM becomes magical using Linear Algebra. Sometimes, data cannot be separated by a straight line (e.g., a red circle inside a blue ring).\n\nThe Concept: Mapping to Higher Dimensions\nWe use a function \\(\\phi(x)\\) to transform our input vector \\(x\\) (2D) into a higher-dimensional vector \\(z\\) (3D or more).\n\nAnalogy: If you have red and blue marbles mixed on a flat table (2D) and can‚Äôt separate them with a stick, you can slap the table (add energy/dimension). The red marbles (lighter) fly higher than the blue ones. Now, you can slide a flat sheet (hyperplane) between the red and blue marbles in mid-air (3D).\n\n\n\nThe Math: Dot Products as Similarity\nSVM relies entirely on the Dot Product (\\(x_i \\cdot x_j\\)). The dot product is a measure of geometric similarity. * If two vectors point in the same direction, their dot product is large. * If they are perpendicular, it is zero.\nThe Kernel Function \\(K(x_i, x_j)\\) allows us to calculate the dot product in that high-dimensional ‚Äúmid-air‚Äù space without actually doing the math to send the points there. This is the ‚ÄúTrick.‚Äù",
    "crumbs": [
      "Home",
      "SVM & LA"
    ]
  },
  {
    "objectID": "pages/slt/svm/index.html#eigenvalues-and-the-gram-matrix",
    "href": "pages/slt/svm/index.html#eigenvalues-and-the-gram-matrix",
    "title": "üéì Support Vector Machines (SVM) and Linear Algebra",
    "section": "üß© 3. Eigenvalues and The Gram Matrix",
    "text": "üß© 3. Eigenvalues and The Gram Matrix\nYou asked how Eigenvalues appear. They are critical to the validity of the Kernel.\nFor a Kernel (like the Gaussian/RBF kernel) to be valid, the matrix of all dot products between all data points (called the Gram Matrix or Kernel Matrix, \\(K\\)) must be Positive Semi-Definite (PSD).\n\nVisualizing the Gram Matrix (\\(K\\))\nImagine a spreadsheet where row \\(i\\) and column \\(j\\) contains the similarity score between data point \\(i\\) and data point \\(j\\).\n\\[K = \\begin{bmatrix}\nx_1 \\cdot x_1 & x_1 \\cdot x_2 & \\dots \\\\\nx_2 \\cdot x_1 & x_2 \\cdot x_2 & \\dots \\\\\n\\vdots & \\vdots & \\ddots\n\\end{bmatrix}\\]\n\n\nThe Role of Eigenvalues (\\(\\lambda\\))\n\nThe Condition: For the math to work (for the optimization to find a unique ‚Äúbest‚Äù solution), all Eigenvalues (\\(\\lambda\\)) of this matrix must be non-negative (\\(\\lambda \\ge 0\\)).\nThe Interpretation: If an eigenvalue is negative, it implies a ‚Äúnegative distance‚Äù or a twisted space where the geometry breaks down. The eigenvalues guarantee that the high-dimensional space we are mapping to ‚Äúexists‚Äù and behaves like normal Euclidean geometry.",
    "crumbs": [
      "Home",
      "SVM & LA"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/gradient-explorer.html",
    "href": "pages/slt/mathematics/calculus/gradient-explorer.html",
    "title": "Session 3 | Assignment 1| The Gradient Explorer",
    "section": "",
    "text": "gradient-explorer",
    "crumbs": [
      "Home",
      "Gradient Explorer"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/gradient-explorer.html#objective-visualizing-gradient-descent-in-linear-regression",
    "href": "pages/slt/mathematics/calculus/gradient-explorer.html#objective-visualizing-gradient-descent-in-linear-regression",
    "title": "Session 3 | Assignment 1| The Gradient Explorer",
    "section": "üéØ Objective: Visualizing Gradient Descent in Linear Regression",
    "text": "üéØ Objective: Visualizing Gradient Descent in Linear Regression\nWe will focus on a simple Linear Regression problem using the Iris dataset (predicting Petal Width from Petal Length) to keep the visualizations 2D and interpretable.\n\nThe Gradient Explorer: Visualizing Learning\nThis solution includes the mathematical derivation, the Python implementation, and a comprehensive breakdown of the resulting visualizations.\n\n\n\n1. The Mathematical Setup\nWe are transforming a static model into a dynamic learner using the ‚ÄúHiker in the Fog‚Äù analogy.\n\nThe Model (The Hiker‚Äôs Position): \\(\\hat{y} = w \\cdot x + b\\)\nWhere:\n\n\\(w\\): Weight (Slope)\n\\(b\\): Bias (Intercept)\n\nThe Loss Function (The Landscape Height): Mean Squared Error (MSE)\n\\(J(w, b) = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - (w \\cdot x_i + b))^2\\)\nWhere:\n\n\\(N\\): Number of data points\n\\(y_i\\): Actual value\n\\(\\hat{y}_i\\): Predicted value\n\nThe Gradient (The Slope under foot):\n\\(\\frac{\\partial J}{\\partial w} = -\\frac{2}{N} \\sum_{i=1}^{N} x_i (y_i - \\hat{y}_i)\\)\n\\(\\frac{\\partial J}{\\partial b} = -\\frac{2}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)\\)\nThe Update Rule (The Step):\n\\(w_{new} = w_{old} - \\alpha \\cdot \\frac{\\partial J}{\\partial w}\\)\n\\(b_{new} = b_{old} - \\alpha \\cdot \\frac{\\partial J}{\\partial b}\\)\nWhere:\n\n\\(\\alpha\\): Learning Rate (Step Size)\n\\(w_{old}, b_{old}\\): Current parameters\n\\(w_{new}, b_{new}\\): Updated parameters\n\n\n\n\n\n2. Python Implementation\nThis code implements Gradient Descent from scratch and generates the requested visualizations: the Loss Surface and the Gradient Path.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n\n# 1. Load Data (Iris Dataset)\n# We will predict Petal Width (y) based on Petal Length (x)\niris = datasets.load_iris()\nx_data = iris.data[:, 2]  # Petal Length\ny_data = iris.data[:, 3]  # Petal Width\n\n# Standardize data for better gradient descent convergence\nx_data = (x_data - np.mean(x_data)) / np.std(x_data)\ny_data = (y_data - np.mean(y_data)) / np.std(y_data)\n\n# 2. Define Functions\ndef compute_loss(w, b, x, y):\n    \"\"\"Mean Squared Error\"\"\"\n    N = len(y)\n    prediction = w * x + b\n    loss = (1/N) * np.sum((y - prediction)**2)\n    return loss\n\ndef compute_gradients(w, b, x, y):\n    \"\"\"Calculates partial derivatives w.r.t w and b\"\"\"\n    N = len(y)\n    prediction = w * x + b\n    # Derivative w.r.t w: mean of -2 * x * error\n    dw = (-2/N) * np.sum(x * (y - prediction))\n    # Derivative w.r.t b: mean of -2 * error\n    db = (-2/N) * np.sum(y - prediction)\n    return dw, db\n\ndef gradient_descent(x, y, start_w, start_b, learning_rate, iterations):\n    w, b = start_w, start_b\n    history = []\n    \n    for i in range(iterations):\n        loss = compute_loss(w, b, x, y)\n        dw, db = compute_gradients(w, b, x, y)\n        \n        # Store history for visualization\n        history.append({'w': w, 'b': b, 'loss': loss})\n        \n        # The Update Rule\n        w = w - learning_rate * dw\n        b = b - learning_rate * db\n        \n    return w, b, history\n\n# 3. Run Experiments with Different Learning Rates\n# Start at a \"bad\" random point to see the journey\nstart_w, start_b = -2.0, -2.0 \niterations = 50\n\nlr_small = 0.05\n_, _, hist_small = gradient_descent(x_data, y_data, start_w, start_b, lr_small, iterations)\n\nlr_large = 0.9\n_, _, hist_large = gradient_descent(x_data, y_data, start_w, start_b, lr_large, iterations)\n\n# 4. Visualization\n# Create the meshgrid for the Loss Surface\nw_range = np.linspace(-3, 3, 100)\nb_range = np.linspace(-3, 3, 100)\nW, B = np.meshgrid(w_range, b_range)\nLoss_Surface = np.zeros_like(W)\n\nfor i in range(W.shape[0]):\n    for j in range(W.shape[1]):\n        Loss_Surface[i, j] = compute_loss(W[i, j], B[i, j], x_data, y_data)\n\n# Plotting\nfig = plt.figure(figsize=(14, 6))\n\n# Plot 1: The Loss Surface and Gradient Path (Learning Rate = 0.1)\nax1 = fig.add_subplot(1, 2, 1, projection='3d')\nax1.plot_surface(W, B, Loss_Surface, cmap='viridis', alpha=0.6)\nax1.set_title(f'Gradient Descent Path (LR={lr_small})\\n\"Controlled Descent\"')\nax1.set_xlabel('Weight (w)')\nax1.set_ylabel('Bias (b)')\nax1.set_zlabel('Loss')\n\n# Extract path data\nw_path = [h['w'] for h in hist_small]\nb_path = [h['b'] for h in hist_small]\nloss_path = [h['loss'] for h in hist_small]\nax1.plot(w_path, b_path, loss_path, color='red', marker='o', markersize=4, label='Path')\n\n# Plot 2: Contour Map comparison (Small vs Large LR)\nax2 = fig.add_subplot(1, 2, 2)\nax2.contour(W, B, Loss_Surface, levels=20, cmap='viridis')\nax2.set_title('Top-Down View: Impact of Learning Rate')\nax2.set_xlabel('Weight (w)')\nax2.set_ylabel('Bias (b)')\n\n# Plot Small LR Path\nax2.plot(w_path, b_path, color='red', marker='o', markersize=3, label=f'LR={lr_small} (Steady)')\n\n# Plot Large LR Path\nw_path_l = [h['w'] for h in hist_large]\nb_path_l = [h['b'] for h in hist_large]\nax2.plot(w_path_l, b_path_l, color='orange', marker='x', linestyle='--', label=f'LR={lr_large} (Overshooting)')\n\nax2.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n3. Analysis of the Visualizations\n\nA. The Loss Surface (The ‚ÄúLandscape‚Äù)\nThe 3D plot visualizes the ‚ÄúConvex‚Äù nature of the Linear Regression loss function.\n\nShape: It looks like a bowl or a valley. This confirms that there is one single ‚ÄúGlobal Minimum‚Äù‚Äîthe bottom of the bowl where the loss is lowest.\nCoordinates: Every point on this surface represents a specific combination of (slope) and (intercept).\nHeight (Z-axis): Represents the Error. High points are ‚Äúbad‚Äù models; low points are ‚Äúgood‚Äù models.\n\n\n\nB. The Gradient Path (The ‚ÄúHiker‚Äù)\nThe red line traces the history of the model‚Äôs learning.\n\nStarting Point: The path begins at , high up on the rim of the bowl. The error is high because the parameters are random.\nThe Trajectory: Notice that the path moves perpendicular to the contour lines. This visualizes the gradient property: pointing in the direction of steepest descent.\nThe Steps: The points are far apart at the beginning (where the slope is steep) and get closer together as they reach the bottom (where the slope flattens out). This shows how the gradient magnitude naturally slows down the learning as we approach the solution.\n\n\n\nC. The Effect of Learning Rate (LR)\nThe 2D Contour plot compares two different ‚ÄúHikers‚Äù:\n\nRed Path (LR = 0.05 - ‚ÄúJust Right‚Äù):\n\n\nThis path moves steadily and directly toward the center (the minimum).\nIt efficiently navigates the valley floor.\n\n\nOrange Path (LR = 0.9 - ‚ÄúToo Large‚Äù):\n\n\nThis path zig-zags violently.\nIt overshoots the valley floor, jumping from one wall of the canyon to the other.\nInterpretation: The ‚Äústeps‚Äù were so big that the hiker missed the bottom and accidentally stepped up the slope on the other side. This illustrates why tuning the learning rate is critical for stability.\n\n\n\n\nConnection to AI Domains\nThis simple ‚ÄúGradient Explorer‚Äù visualizes the exact same mechanism used in massive neural networks:\n\nComputer Vision: The ‚Äúlandscape‚Äù is non-convex and millions of dimensions, but the ‚Äúhiker‚Äù (Optimizer) still follows the gradient downhill.\nNLP (Transformers): The ‚ÄúAttention Mechanism‚Äù gradients direct the hiker toward which words matter most.\nRecommender Systems: Matrix Factorization uses this same alternating gradient descent to minimize the difference between predicted ratings and actual user preferences.",
    "crumbs": [
      "Home",
      "Gradient Explorer"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/linear-algebra/analogy-1.html",
    "href": "pages/slt/mathematics/linear-algebra/analogy-1.html",
    "title": "AIML Course",
    "section": "",
    "text": "analogy-1",
    "crumbs": [
      "Home",
      "Analogies LA"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/linear-algebra/analogy-1.html#matrix-multiplication-the-outfit-designer-story",
    "href": "pages/slt/mathematics/linear-algebra/analogy-1.html#matrix-multiplication-the-outfit-designer-story",
    "title": "AIML Course",
    "section": "1. Matrix Multiplication ‚Äì The Outfit Designer Story",
    "text": "1. Matrix Multiplication ‚Äì The Outfit Designer Story\n\nYou‚Äôre helping a school design outfits for different events: sports day, annual day, and farewell. You have shirts, pants, and shoes in different colors.\n\n\n‚ÄúWe can think of the clothes as numbers in a list ‚Äî like a vector ‚Äî and the outfit designer‚Äôs plan as a matrix.‚Äù\n\nLet‚Äôs define:\n\\(\\text{Vector of available clothes:} v = \\begin{bmatrix} 2 \\\\ 3 \\\\ 1 \\end{bmatrix}\\)\n(where 2 shirts, 3 pants, and 1 pair of shoes are available).\nAnd the style matrix for creating different outfits:\n\\(M = \\begin{bmatrix}\n1 & 0 & 1 \\\\   % sports outfit\n0 & 1 & 1 \\\\   % annual day outfit\n1 & 1 & 0      % farewell outfit\n\\end{bmatrix}\\)\n\nRow 1 = Sports outfit uses 1 shirt + 0 pant + 1 shoe.\n\nRow 2 = Annual outfit uses 0 shirt + 1 pant + 1 shoe.\n\nRow 3 = Farewell outfit uses 1 shirt + 1 pant + 0 shoe.\n\nMatrix multiplication:\n\\(M \\times v =\n\\begin{bmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1 \\\\\n1 & 1 & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n2 \\\\ 3 \\\\ 1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n(1√ó2 + 0√ó3 + 1√ó1) \\\\\n(0√ó2 + 1√ó3 + 1√ó1) \\\\\n(1√ó2 + 1√ó3 + 0√ó1)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n3 \\\\ 4 \\\\ 5\n\\end{bmatrix}\\)\n\n‚ÄúThis means we can make 3 sports outfits, 4 annual day outfits, and 5 farewell outfits. The matrix acted like a recipe book that transformed our list of clothes into finished outfits.‚Äù",
    "crumbs": [
      "Home",
      "Analogies LA"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/linear-algebra/analogy-1.html#eigenvectors-and-eigenvalues-the-stretchy-line-story",
    "href": "pages/slt/mathematics/linear-algebra/analogy-1.html#eigenvectors-and-eigenvalues-the-stretchy-line-story",
    "title": "AIML Course",
    "section": "2. Eigenvectors and Eigenvalues ‚Äì The Stretchy Line Story",
    "text": "2. Eigenvectors and Eigenvalues ‚Äì The Stretchy Line Story\n\nImagine you draw lines on a rubber sheet ‚Äî one horizontal, one diagonal. Now you stretch the sheet by pulling it rightward.\n\n\n‚ÄúSome lines will twist and tilt, but one or two special lines won‚Äôt turn direction; they only get longer or shorter.‚Äù\n\nWe can represent the transformation as:\n\\(A = \\begin{bmatrix} 2 & 0 \\\\ 0 & 1 \\end{bmatrix}\\)\nThis means x-values are doubled, but y-values stay the same.\nFor a vector along the x-axis:\n\\(v_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\\)\nthen\n\\(A v_1 = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} = 2 v_1\\)\nThus, \\(v_1\\) doesn‚Äôt change direction ‚Äî only its length doubles. Its eigenvalue is \\(2\\).\nFor a vector along the y-axis:\n\\(v_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\) then\n\\(A.v_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = 1 v_2\\)\nHere, the direction stays the same, and the eigenvalue is \\(1\\).\nTeacher explains:\n&gt; ‚ÄúThe eigenvectors are the lines that don‚Äôt rotate when stretched, only change in size. The eigenvalues tell how much each line grows or shrinks.‚Äù",
    "crumbs": [
      "Home",
      "Analogies LA"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/linear-algebra/analogy-1.html#dimensionality-reduction-the-shadow-story",
    "href": "pages/slt/mathematics/linear-algebra/analogy-1.html#dimensionality-reduction-the-shadow-story",
    "title": "AIML Course",
    "section": "3. Dimensionality Reduction ‚Äì The Shadow Story",
    "text": "3. Dimensionality Reduction ‚Äì The Shadow Story\n\nYou have a 3D toy (a cube) lit by a lamp. Its shadow falls on the wall ‚Äî a 2D picture that keeps most of the cube‚Äôs shape.\n\n\n‚ÄúWhen we look at the shadow, we‚Äôre reducing a 3D object to 2D, keeping its most important features.‚Äù\n\nLet‚Äôs imagine three points on the cube in 3D space:\n\\(P_1 = (1, 2, 3), \\quad P_2 = (2, 3, 4), \\quad P_3 = (3, 5, 6)\\)\nTo project onto a 2D plane (ignore the z-axis):\n\\(\\text{Projection matrix }\nP = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0\n\\end{bmatrix}\\)\nThen:\n\\(P \\times\n\\begin{bmatrix}\n1 \\\\ 2 \\\\ 3\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 \\\\ 2\n\\end{bmatrix},\n\\quad\nP \\times\n\\begin{bmatrix}\n2 \\\\ 3 \\\\ 4\n\\end{bmatrix}=\n\\begin{bmatrix}\n2 \\\\ 3\n\\end{bmatrix},\n\\quad\nP \\times\n\\begin{bmatrix}\n3 \\\\ 5 \\\\ 6\n\\end{bmatrix}=\n\\begin{bmatrix}\n3 \\\\ 5\n\\end{bmatrix}\\)\n\n‚ÄúThe shadow keeps the main structure ‚Äî how points relate ‚Äî but loses some details (depth). That‚Äôs exactly what dimensionality reduction like PCA does: it keeps the most useful parts and drops unnecessary ones.‚Äù",
    "crumbs": [
      "Home",
      "Analogies LA"
    ]
  },
  {
    "objectID": "pages/slt/logistic-regression/index.html#what-is-logistic-regression",
    "href": "pages/slt/logistic-regression/index.html#what-is-logistic-regression",
    "title": "üéì Logistic Regression Essentials",
    "section": "üéØ What is Logistic Regression?",
    "text": "üéØ What is Logistic Regression?\nLogistic Regression is one of the most fundamental and widely used algorithms for classification tasks in Machine Learning.\n\nLinear Regression predicts a continuous value (like house price, temperature).\nLogistic Regression predicts a category or probability (like: Will this customer click an ad? Yes/No.¬†Is this email spam? Yes/No).\n\nThe key idea is that instead of predicting the value \\(Y\\) itself, Logistic Regression predicts the probability \\(P(Y=1)\\) that a given input belongs to a certain class. It then uses a special function, called the Sigmoid Function to squash any output into a probability score between 0 and 1. The Sigmoid Function is defined as:\n\\(P(Y=1) = \\frac{1}{1 + e^{-(X \\cdot W)}}\\) ,\nThe Sigmoid function takes the linear combination of input features (\\(X\\)) and weights (\\(W\\)) and transforms it into a probability.\nThe output can then be thresholded (commonly at 0.5) to make a binary classification decision:\n\nIf \\(P(Y=1) \\geq 0.5\\), predict class 1 (YES).\nIf \\(P(Y=1) &lt; 0.5\\), predict class 0 (NO).\n\nThe Sigmoid function has an ‚ÄúS‚Äù-shaped curve that smoothly transitions from 0 to 1, making it ideal for modeling probabilities.\nThe logistic curve is shown below: \n\nAnalogy: The Probability Gatekeeper\nImagine a ‚ÄúProbability Gatekeeper‚Äù with a dial that can only point to values between 0 and 1.\n\nA standard Linear Regression model first calculates a raw score for a data point (this score can be any number, e.g., \\(-10\\), \\(0\\), \\(50\\)). This is the input to the Gatekeeper.\nThe Gatekeeper (the Sigmoid Function) takes this raw score and transforms it:\n\nVery large positive scores get turned into a probability close to \\(\\mathbf{1}\\) (High Confidence: YES).\nVery large negative scores get turned into a probability close to \\(\\mathbf{0}\\) (High Confidence: NO).\nA score of \\(\\mathbf{0}\\) gets turned into a probability of \\(\\mathbf{0.5}\\) (Uncertain).\n\n\nThis transformation allows us to use a linear model for a non-linear classification problem.",
    "crumbs": [
      "Home",
      "Logistic Regression"
    ]
  },
  {
    "objectID": "pages/slt/logistic-regression/index.html#deconstructing-logistic-regression-through-the-four-lenses",
    "href": "pages/slt/logistic-regression/index.html#deconstructing-logistic-regression-through-the-four-lenses",
    "title": "üéì Logistic Regression Essentials",
    "section": "üèóÔ∏è Deconstructing Logistic Regression Through the Four Lenses",
    "text": "üèóÔ∏è Deconstructing Logistic Regression Through the Four Lenses\n\n1. The Linear Algebra Perspective: Data as Mathematical Objects\nCore Idea: Linear Algebra provides the blueprint for how we structure data and calculate the raw score.\n\n\n\n\n\n\n\n\nComponent\nLinear Algebra Mapping\nAnalogy\n\n\n\n\nInput Features\nA Design Matrix (\\(X\\))\nA collection of ingredients for a recipe (e.g., age, income, time spent on site).\n\n\nModel Parameters\nA Weight Vector (\\(W\\))\nA scaling factor for each ingredient (how important is age vs.¬†income?).\n\n\nRaw Score Calculation\nMatrix-Vector Multiplication (\\(X \\cdot W\\))\nThe initial mixing of ingredients to get a base flavor (the raw score).\n\n\n\nJust as in linear regression, the initial step in logistic regression is fundamentally a linear transformation: a weighted sum of the input features. This provides the logit, or log-odds, which is the raw, unbounded score that the Sigmoid function will process.\n\n\n2. The Statistical Foundation: Measuring and Modeling Uncertainty\nCore Idea: Probability & Statistics provides the specific function to model the probability and the metric to measure the model‚Äôs performance.\n\n\n\n\n\n\n\n\nComponent\nStatistical Mapping\nAnalogy\n\n\n\n\nPrediction Function\nSigmoid Function (\\(P = \\frac{1}{1 + e^{-(X \\cdot W)}}\\))\nThe Probability Gatekeeper that converts the raw score into a \\(0\\) to \\(1\\) probability.\n\n\nLoss Function\nLog-Loss (or Binary Cross-Entropy)\nThe Critic‚Äôs Scorecard. Instead of measuring squared distance, it heavily penalizes confident wrong predictions.\n\n\n\nIn classification, we care about assigning the correct probability to the correct class. If the model predicts an event will happen with \\(P=0.9\\) (90% sure) but it doesn‚Äôt happen, the Log-Loss gives a massive penalty. Conversely, if it predicts \\(P=0.1\\) and the event doesn‚Äôt happen, the penalty is small. This function is derived from the principle of Maximum Likelihood Estimation, which seeks the model parameters that make the observed data most probable.\n\\[L(W) = - \\frac{1}{N} \\sum_{i=1}^N \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\\]\n\n\n3. The Calculus Engine: The Mathematics of Improvement\nCore Idea: Calculus provides the tool to efficiently determine how to adjust the model parameters to minimize the error.\n\n\n\n\n\n\n\n\nComponent\nCalculus Mapping\nAnalogy\n\n\n\n\nOptimization Direction\nThe Gradient (\\(\\nabla L\\))\nThe Compass Needle. It points in the direction of steepest ascent (worst performance).\n\n\nLearning Mechanism\nPartial Derivatives\nThe Sensitivity Report. For every weight, it tells you: ‚ÄúIf I slightly increase this weight, how much will the total error change?‚Äù\n\n\n\nTo make the model better, we must take steps in the opposite direction of the gradient (\\(\\mathbf{- \\nabla L}\\)). Calculating the gradient of the complex Log-Loss function involves the Chain Rule, where we compute the derivative of the loss with respect to the prediction, then the derivative of the prediction (Sigmoid) with respect to the raw score, and finally the derivative of the raw score with respect to the weights. This systematic calculation is the engine of learning.\n\n\n4. The Optimization Process: The Journey to Better Solutions\nCore Idea: Optimization is the strategy for navigating the error landscape and finding the best set of weights.\n\n\n\n\n\n\n\n\nComponent\nOptimization Mapping\nAnalogy\n\n\n\n\nAlgorithm\nGradient Descent (or its variants)\nThe Mountain Climber. The climber starts somewhere on the error mountain and takes repeated, calculated steps downhill.\n\n\nLearning Rate\nStep Size (\\(\\alpha\\))\nThe Length of the Stride. Too large, and you might jump right over the minimum; too small, and the journey will take forever.\n\n\nStopping Condition\nConvergence Criteria\nThe Summit Signal. Stop climbing when your steps downhill no longer meaningfully improve your altitude (error).\n\n\n\nOptimization takes the direction provided by Calculus and applies a disciplined strategy (Gradient Descent) to find the weights that minimize the Log-Loss. By iteratively updating the weight vector \\(W\\) using the rule: \\(W_{new} = W_{old} - \\alpha \\cdot \\nabla L\\), we ensure the model continuously improves its ability to correctly separate the classes.",
    "crumbs": [
      "Home",
      "Logistic Regression"
    ]
  },
  {
    "objectID": "pages/slt/logistic-regression/index.html#sample-code-logistic-regression-in-python",
    "href": "pages/slt/logistic-regression/index.html#sample-code-logistic-regression-in-python",
    "title": "üéì Logistic Regression Essentials",
    "section": "üíª Sample Code: Logistic Regression in Python",
    "text": "üíª Sample Code: Logistic Regression in Python\nHere is a simple example using the popular scikit-learn library to perform a Logistic Regression classification.\n# Import necessary libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\n# 1. Prepare Synthetic Data (Feature X, Target Y)\n# X: Study hours, Y: Pass/Fail (1/0)\nX = np.array([[0.5], [1.0], [2.2], [3.1], [4.5], [5.0], [6.8], [7.2], [8.0], [9.5]])\ny = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1]) # 1 = Pass, 0 = Fail\n\n# Reshape X for scikit-learn\nX = X.reshape(-1, 1)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 2. Initialize and Train the Model\nmodel = LogisticRegression()\n# The .fit() method here is the Optimization process (Gradient Descent)\nmodel.fit(X_train, y_train) \n\n# 3. Make Predictions\n# Predict class labels (0 or 1)\npredictions = model.predict(X_test)\n# Predict probabilities (e.g., 0.95, 0.12)\nprobabilities = model.predict_proba(X_test) \n\n# 4. Evaluate Performance\naccuracy = accuracy_score(y_test, predictions)\n\nprint(f\"Model Intercept (b0): {model.intercept_[0]:.2f}\")\nprint(f\"Model Coefficient (w1): {model.coef_[0][0]:.2f}\")\nprint(f\"Accuracy on Test Data: {accuracy:.2f}\")\nprint(\"\\nProbabilities for Test Data:\")\nprint(probabilities)",
    "crumbs": [
      "Home",
      "Logistic Regression"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aritificial Intelligence and Machine Learning",
    "section": "",
    "text": "This is the home page for the Artificial Intelligence and Machine Learning training program. Here you will find resources, papers, and workshops related to AI and ML. Feel free to explore the site using the navigation bar above."
  },
  {
    "objectID": "pages/slt/mathematics/linear-algebra/connection-map.html",
    "href": "pages/slt/mathematics/linear-algebra/connection-map.html",
    "title": "AIML Course",
    "section": "",
    "text": "Session 2 | Assignment 3| The Connection Map\n\n\n\nconnection-map",
    "crumbs": [
      "Home",
      "Connection Map LA"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/optimzation.html",
    "href": "pages/slt/mathematics/calculus/optimzation.html",
    "title": "Session 3 | Assignment 3| The Optimization Strategist",
    "section": "",
    "text": "optimization\n\n\nImagine three different hikers are dropped at a random spot high up on a foggy mountain range. Their goal is to find the lowest valley (the Global Minimum) where the village (Optimal Solution) is located. They cannot see the map; they can only feel the slope under their feet.\nThe three hikers are Mr.¬†SGD, Ms.¬†Momentum, and Dr.¬†Adam.\n\n\n\n\n\n\n\nThe Strategy: He takes a single small step, looks at the ground right beneath his feet, calculates the slope, and takes a step downhill. He repeats this thousands of times.\nThe Analogy: A careful but slightly erratic walker. Because he looks at only a small patch of ground (a ‚Äúbatch‚Äù of data) at a time, he zig-zags a lot. If the terrain is bumpy, he might get thrown off course easily.\n\n\n\n\n\nThe Strategy: She remembers her previous steps. If she has been moving downhill for a while, she builds up speed (velocity). Even if she hits a small bump or a flat patch, her built-up inertia carries her through.\nThe Analogy: A heavy bowling ball rolling down the hill. She gains speed and cuts through the noise. She doesn‚Äôt zig-zag as much because her momentum keeps her moving in the general right direction.\n\n\n\n\n\nThe Strategy: He is the smartest hiker. He keeps track of two things:\n\n\nMomentum: Like Ms.¬†Momentum, he knows the general direction he‚Äôs been heading.\nTerrain Adaptation: He notices if the slope is changing wildly or is steady. If the terrain is rough and unpredictable (high variance), he takes smaller, careful steps. If the terrain is smooth and steady, he takes larger, confident strides.\n\n\nThe Analogy: A high-tech rover with adaptive suspension. He adjusts his speed and stability for every single dimension of the terrain individually.\n\n\n\n\n\n\nHere is how they perform on a standard classification task (like classifying images of cats and dogs).\n\n\n\n\n\n\n\n\n\nFeature\nüö∂ SGD\n‚õ∑Ô∏è Momentum\nüß† Adam\n\n\n\n\nConvergence Speed\nSlow. It takes many small, noisy steps to get to the bottom.\nFast. Accelerates through flat areas and dampens oscillations.\nFastest. The adaptive learning rate allows it to jump quickly toward the solution early on.\n\n\nFinal Performance\nGood (eventually). Can settle into a very precise minimum if given enough time and a scheduled learning rate decay.\nBetter. Often finds better solutions than SGD because it powers through shallow local minima.\nExcellent. Generally achieves high accuracy very quickly, though sometimes SGD generalizes slightly better at the very end.\n\n\nSensitivity to Learning Rate\nHigh. Very sensitive. If the rate is too high, it diverges; too low, it never finishes. Requires constant manual tuning.\nMedium. The momentum term stabilizes it, but you still need to tune the learning rate carefully.\nLow. Very robust. The default learning rate (usually 0.001) works for a vast majority of problems without tuning.\n\n\nComputational Cost\nLowest. Very simple math (subtraction and multiplication). Uses minimal memory.\nLow/Medium. Needs to store a velocity vector (doubles memory for gradients).\nMedium/High. Needs to store moving averages of gradients and squared gradients (triples memory for gradients).\n\n\n\n\n\n\n\n\nSGD creates a zig-zag path, bouncing off the walls of the valley on its way down.\nMomentum creates a smoother curve. It might overshoot the bottom slightly (like a ball rolling up the other side) but settles back down quickly.\nAdam creates a direct line. It acts like a guided missile, adjusting its trajectory immediately to head straight for the center.\n\n\n\n\n\n\n\n\nYou want results fast: It is the ‚Äúdefault‚Äù choice for most deep learning projects today (Transformers, CNNs).\nYou don‚Äôt want to tune hyperparameters: You want to press ‚Äútrain‚Äù and get a good result without spending days finding the perfect learning rate.\nThe data is sparse: (e.g., NLP tasks) where some features appear very rarely. Adam‚Äôs adaptive nature handles this perfectly.\n\n\n\n\n\nYou need absolute state-of-the-art precision: In some computer vision research papers, SGD (with careful tuning) is shown to generalize slightly better than Adam on the test set.\nMemory is extremely tight: If you are running a massive model on a small device, the lower memory footprint of SGD might be necessary.\n\n\n\n\n\nYou are training on a consistent, smooth landscape: And you want the speed of acceleration but standard SGD is too slow. (Note: Most modern implementations just use Adam or SGD-with-Momentum; ‚Äúplain‚Äù Momentum is rarely used alone).\n\n\n\n\n\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.datasets import make_moons\n\n# ==========================================\n# 1. SETUP: Create the \"Terrain\" (Data)\n# ==========================================\n# We generate a \"Moon\" shaped dataset which is hard for linear models\nX, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n\n# Convert to PyTorch tensors (The format the hikers understand)\nX_tensor = torch.FloatTensor(X)\ny_tensor = torch.FloatTensor(y).reshape(-1, 1)\n\n# ==========================================\n# 2. THE HIKER (The Model Architecture)\n# ==========================================\n# A simple neural network with one hidden layer\ndef get_model():\n    model = nn.Sequential(\n        nn.Linear(2, 50),   # Input: 2 coordinates -&gt; Hidden: 50 neurons\n        nn.ReLU(),          # Activation\n        nn.Linear(50, 1),   # Hidden: 50 neurons -&gt; Output: 1 prediction\n        nn.Sigmoid()        # Probability (0 to 1)\n    )\n    return model\n\n# ==========================================\n# 3. THE RACE (Training Loop)\n# ==========================================\ndef train_model(optimizer_name, learning_rate=0.01):\n    model = get_model()\n    criterion = nn.BCELoss() # Binary Cross Entropy Loss\n    \n    # Assign the specific Hiker (Optimizer)\n    if optimizer_name == \"SGD\":\n        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n    elif optimizer_name == \"Momentum\":\n        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n    elif optimizer_name == \"Adam\":\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n        \n    losses = []\n    \n    # The Race: 100 Steps (Epochs)\n    for epoch in range(100):\n        # 1. Forward Pass (Make prediction)\n        outputs = model(X_tensor)\n        loss = criterion(outputs, y_tensor)\n        \n        # 2. Backward Pass (Calculate Gradient)\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # 3. Step (Update Weights)\n        optimizer.step()\n        \n        losses.append(loss.item())\n        \n    return losses\n\n# ==========================================\n# 4. RUNNING THE RACE\n# ==========================================\nprint(\"üèÅ Starting the race...\")\nloss_sgd = train_model(\"SGD\")\nloss_momentum = train_model(\"Momentum\")\nloss_adam = train_model(\"Adam\")\n\n# ==========================================\n# 5. VISUALIZING THE FINISH LINE\n# ==========================================\nplt.figure(figsize=(10, 6))\nplt.plot(loss_sgd, label='SGD (The Walker)', linestyle='--', color='red')\nplt.plot(loss_momentum, label='Momentum (The Bowler)', linestyle='-.', color='blue')\nplt.plot(loss_adam, label='Adam (The Rover)', linewidth=3, color='green')\n\nplt.title('The Optimization Race: Loss over Time')\nplt.xlabel('Steps (Epochs)')\nplt.ylabel('Loss (Error)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.5 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11&gt;=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy&lt;2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"&lt;frozen runpy&gt;\", line 198, in _run_module_as_main\n  File \"&lt;frozen runpy&gt;\", line 88, in _run_code\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in &lt;module&gt;\n    app.launch_new_instance()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n    self.io_loop.start()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n    self._run_once()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n    handle._run()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n    await self.dispatch_shell(msg, subshell_id=subshell_id)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n    await result\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n    reply_content = await reply_content\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n    res = shell.run_cell(\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n    result = self._run_cell(\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n    result = runner(coro)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/ls/qkb453bd3xl7c7yp9n0rszdh0000gn/T/ipykernel_12332/1151517320.py\", line 1, in &lt;module&gt;\n    import torch\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in &lt;module&gt;\n    from .functional import *  # noqa: F403\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/functional.py\", line 9, in &lt;module&gt;\n    import torch.nn.functional as F\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in &lt;module&gt;\n    from .modules import *  # noqa: F403\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in &lt;module&gt;\n    from .transformer import TransformerEncoder, TransformerDecoder, \\\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in &lt;module&gt;\n    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning:\n\nFailed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n\n\n\nüèÅ Starting the race...\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen you run this, the graph will reveal the distinct personalities of our hikers:\n\nThe Green Line (Adam): You will see this line drop vertically right at the start. It adapts immediately and reaches a low error (near 0.3) within just 10-15 steps. It is the clear winner in the sprint.\nThe Blue Line (Momentum): This line will start slower than Adam but will pick up speed. By step 40 or 50, it often catches up to Adam. The curve is smooth, showing how the ‚Äúvelocity‚Äù helps it plow through the data.\nThe Red Line (SGD): This line will likely descend very slowly. It might look like a gentle slope. In 100 steps, it may barely reach the error level that Adam reached in step 5. This visually demonstrates why standard SGD is rarely used without help in modern Deep Learning.\n\nTakeaway: This simulation proves why Adam is the default ‚ÄúGo-To‚Äù for quick prototyping, while Momentum is essential if you stick with SGD.",
    "crumbs": [
      "Home",
      "Optimization Strategist"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/optimzation.html#the-scenario-the-misty-mountain-descent",
    "href": "pages/slt/mathematics/calculus/optimzation.html#the-scenario-the-misty-mountain-descent",
    "title": "Session 3 | Assignment 3| The Optimization Strategist",
    "section": "",
    "text": "optimization\n\n\nImagine three different hikers are dropped at a random spot high up on a foggy mountain range. Their goal is to find the lowest valley (the Global Minimum) where the village (Optimal Solution) is located. They cannot see the map; they can only feel the slope under their feet.\nThe three hikers are Mr.¬†SGD, Ms.¬†Momentum, and Dr.¬†Adam.",
    "crumbs": [
      "Home",
      "Optimization Strategist"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/optimzation.html#the-competitors-the-algorithms",
    "href": "pages/slt/mathematics/calculus/optimzation.html#the-competitors-the-algorithms",
    "title": "Session 3 | Assignment 3| The Optimization Strategist",
    "section": "",
    "text": "The Strategy: He takes a single small step, looks at the ground right beneath his feet, calculates the slope, and takes a step downhill. He repeats this thousands of times.\nThe Analogy: A careful but slightly erratic walker. Because he looks at only a small patch of ground (a ‚Äúbatch‚Äù of data) at a time, he zig-zags a lot. If the terrain is bumpy, he might get thrown off course easily.\n\n\n\n\n\nThe Strategy: She remembers her previous steps. If she has been moving downhill for a while, she builds up speed (velocity). Even if she hits a small bump or a flat patch, her built-up inertia carries her through.\nThe Analogy: A heavy bowling ball rolling down the hill. She gains speed and cuts through the noise. She doesn‚Äôt zig-zag as much because her momentum keeps her moving in the general right direction.\n\n\n\n\n\nThe Strategy: He is the smartest hiker. He keeps track of two things:\n\n\nMomentum: Like Ms.¬†Momentum, he knows the general direction he‚Äôs been heading.\nTerrain Adaptation: He notices if the slope is changing wildly or is steady. If the terrain is rough and unpredictable (high variance), he takes smaller, careful steps. If the terrain is smooth and steady, he takes larger, confident strides.\n\n\nThe Analogy: A high-tech rover with adaptive suspension. He adjusts his speed and stability for every single dimension of the terrain individually.",
    "crumbs": [
      "Home",
      "Optimization Strategist"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/optimzation.html#comparative-analysis",
    "href": "pages/slt/mathematics/calculus/optimzation.html#comparative-analysis",
    "title": "Session 3 | Assignment 3| The Optimization Strategist",
    "section": "",
    "text": "Here is how they perform on a standard classification task (like classifying images of cats and dogs).\n\n\n\n\n\n\n\n\n\nFeature\nüö∂ SGD\n‚õ∑Ô∏è Momentum\nüß† Adam\n\n\n\n\nConvergence Speed\nSlow. It takes many small, noisy steps to get to the bottom.\nFast. Accelerates through flat areas and dampens oscillations.\nFastest. The adaptive learning rate allows it to jump quickly toward the solution early on.\n\n\nFinal Performance\nGood (eventually). Can settle into a very precise minimum if given enough time and a scheduled learning rate decay.\nBetter. Often finds better solutions than SGD because it powers through shallow local minima.\nExcellent. Generally achieves high accuracy very quickly, though sometimes SGD generalizes slightly better at the very end.\n\n\nSensitivity to Learning Rate\nHigh. Very sensitive. If the rate is too high, it diverges; too low, it never finishes. Requires constant manual tuning.\nMedium. The momentum term stabilizes it, but you still need to tune the learning rate carefully.\nLow. Very robust. The default learning rate (usually 0.001) works for a vast majority of problems without tuning.\n\n\nComputational Cost\nLowest. Very simple math (subtraction and multiplication). Uses minimal memory.\nLow/Medium. Needs to store a velocity vector (doubles memory for gradients).\nMedium/High. Needs to store moving averages of gradients and squared gradients (triples memory for gradients).",
    "crumbs": [
      "Home",
      "Optimization Strategist"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/optimzation.html#visualizing-the-descent",
    "href": "pages/slt/mathematics/calculus/optimzation.html#visualizing-the-descent",
    "title": "Session 3 | Assignment 3| The Optimization Strategist",
    "section": "",
    "text": "SGD creates a zig-zag path, bouncing off the walls of the valley on its way down.\nMomentum creates a smoother curve. It might overshoot the bottom slightly (like a ball rolling up the other side) but settles back down quickly.\nAdam creates a direct line. It acts like a guided missile, adjusting its trajectory immediately to head straight for the center.",
    "crumbs": [
      "Home",
      "Optimization Strategist"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/optimzation.html#the-strategists-verdict-when-to-choose-which",
    "href": "pages/slt/mathematics/calculus/optimzation.html#the-strategists-verdict-when-to-choose-which",
    "title": "Session 3 | Assignment 3| The Optimization Strategist",
    "section": "",
    "text": "You want results fast: It is the ‚Äúdefault‚Äù choice for most deep learning projects today (Transformers, CNNs).\nYou don‚Äôt want to tune hyperparameters: You want to press ‚Äútrain‚Äù and get a good result without spending days finding the perfect learning rate.\nThe data is sparse: (e.g., NLP tasks) where some features appear very rarely. Adam‚Äôs adaptive nature handles this perfectly.\n\n\n\n\n\nYou need absolute state-of-the-art precision: In some computer vision research papers, SGD (with careful tuning) is shown to generalize slightly better than Adam on the test set.\nMemory is extremely tight: If you are running a massive model on a small device, the lower memory footprint of SGD might be necessary.\n\n\n\n\n\nYou are training on a consistent, smooth landscape: And you want the speed of acceleration but standard SGD is too slow. (Note: Most modern implementations just use Adam or SGD-with-Momentum; ‚Äúplain‚Äù Momentum is rarely used alone).\n\n\n\n\n\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.datasets import make_moons\n\n# ==========================================\n# 1. SETUP: Create the \"Terrain\" (Data)\n# ==========================================\n# We generate a \"Moon\" shaped dataset which is hard for linear models\nX, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n\n# Convert to PyTorch tensors (The format the hikers understand)\nX_tensor = torch.FloatTensor(X)\ny_tensor = torch.FloatTensor(y).reshape(-1, 1)\n\n# ==========================================\n# 2. THE HIKER (The Model Architecture)\n# ==========================================\n# A simple neural network with one hidden layer\ndef get_model():\n    model = nn.Sequential(\n        nn.Linear(2, 50),   # Input: 2 coordinates -&gt; Hidden: 50 neurons\n        nn.ReLU(),          # Activation\n        nn.Linear(50, 1),   # Hidden: 50 neurons -&gt; Output: 1 prediction\n        nn.Sigmoid()        # Probability (0 to 1)\n    )\n    return model\n\n# ==========================================\n# 3. THE RACE (Training Loop)\n# ==========================================\ndef train_model(optimizer_name, learning_rate=0.01):\n    model = get_model()\n    criterion = nn.BCELoss() # Binary Cross Entropy Loss\n    \n    # Assign the specific Hiker (Optimizer)\n    if optimizer_name == \"SGD\":\n        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n    elif optimizer_name == \"Momentum\":\n        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n    elif optimizer_name == \"Adam\":\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n        \n    losses = []\n    \n    # The Race: 100 Steps (Epochs)\n    for epoch in range(100):\n        # 1. Forward Pass (Make prediction)\n        outputs = model(X_tensor)\n        loss = criterion(outputs, y_tensor)\n        \n        # 2. Backward Pass (Calculate Gradient)\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # 3. Step (Update Weights)\n        optimizer.step()\n        \n        losses.append(loss.item())\n        \n    return losses\n\n# ==========================================\n# 4. RUNNING THE RACE\n# ==========================================\nprint(\"üèÅ Starting the race...\")\nloss_sgd = train_model(\"SGD\")\nloss_momentum = train_model(\"Momentum\")\nloss_adam = train_model(\"Adam\")\n\n# ==========================================\n# 5. VISUALIZING THE FINISH LINE\n# ==========================================\nplt.figure(figsize=(10, 6))\nplt.plot(loss_sgd, label='SGD (The Walker)', linestyle='--', color='red')\nplt.plot(loss_momentum, label='Momentum (The Bowler)', linestyle='-.', color='blue')\nplt.plot(loss_adam, label='Adam (The Rover)', linewidth=3, color='green')\n\nplt.title('The Optimization Race: Loss over Time')\nplt.xlabel('Steps (Epochs)')\nplt.ylabel('Loss (Error)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.5 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11&gt;=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy&lt;2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"&lt;frozen runpy&gt;\", line 198, in _run_module_as_main\n  File \"&lt;frozen runpy&gt;\", line 88, in _run_code\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in &lt;module&gt;\n    app.launch_new_instance()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n    self.io_loop.start()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n    self._run_once()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n    handle._run()\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n    await self.dispatch_shell(msg, subshell_id=subshell_id)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n    await result\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n    reply_content = await reply_content\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n    res = shell.run_cell(\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n    result = self._run_cell(\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n    result = runner(coro)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/var/folders/ls/qkb453bd3xl7c7yp9n0rszdh0000gn/T/ipykernel_12332/1151517320.py\", line 1, in &lt;module&gt;\n    import torch\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in &lt;module&gt;\n    from .functional import *  # noqa: F403\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/functional.py\", line 9, in &lt;module&gt;\n    import torch.nn.functional as F\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in &lt;module&gt;\n    from .modules import *  # noqa: F403\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in &lt;module&gt;\n    from .transformer import TransformerEncoder, TransformerDecoder, \\\n  File \"/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in &lt;module&gt;\n    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n/Users/ahk/miniconda/envs/quarto/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning:\n\nFailed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n\n\n\nüèÅ Starting the race...\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen you run this, the graph will reveal the distinct personalities of our hikers:\n\nThe Green Line (Adam): You will see this line drop vertically right at the start. It adapts immediately and reaches a low error (near 0.3) within just 10-15 steps. It is the clear winner in the sprint.\nThe Blue Line (Momentum): This line will start slower than Adam but will pick up speed. By step 40 or 50, it often catches up to Adam. The curve is smooth, showing how the ‚Äúvelocity‚Äù helps it plow through the data.\nThe Red Line (SGD): This line will likely descend very slowly. It might look like a gentle slope. In 100 steps, it may barely reach the error level that Adam reached in step 5. This visually demonstrates why standard SGD is rarely used without help in modern Deep Learning.\n\nTakeaway: This simulation proves why Adam is the default ‚ÄúGo-To‚Äù for quick prototyping, while Momentum is essential if you stick with SGD.",
    "crumbs": [
      "Home",
      "Optimization Strategist"
    ]
  },
  {
    "objectID": "pages/slt/mathematics/calculus/back-propagation.html",
    "href": "pages/slt/mathematics/calculus/back-propagation.html",
    "title": "The Backpropagation Story: ‚ÄúPassing the Blame‚Äù",
    "section": "",
    "text": "Session 3 | Assignment 2| The Backpropagation Storyteller\n\n\nThe Backpropagation Story: ‚ÄúPassing the Blame‚Äù\n\n\n\nback-propagation\n\n\n\nThe Scenario: The Mini Neural Network\nImagine a tiny factory (Neural Network) that takes two raw ingredients (Inputs) and tries to produce a specific alloy (Output).\nThe Architecture:\n\nInput Layer: 2 Neurons (\\(x_1\\), \\(x_2\\))\nHidden Layer: 1 Neuron (\\(h_1\\)) with a Sigmoid activation.\nOutput Layer: 1 Neuron (\\(y_{pred}\\)) with a Sigmoid activation.\nGoal: For inputs \\(x_1=0.5, x_2=1.0\\), we want the output to be 1.0.\n\n\n\n\nStep 1: The Forward Pass (Making the Product)\nThe factory runs a test batch to see what it currently produces.\n1. Initial Weights (Randomly Assigned):\n\nWeights from Input to Hidden: \\(w_1 = 0.5\\), \\(w_2 = 0.5\\)\nWeight from Hidden to Output: \\(w_3 = 1.0\\)\n\n2. Hidden Layer Calculation:\n\nWeighted Sum (\\(z_1\\)):\n\n\\(z_1 = (x_1 \\cdot w_1) + (x_2 \\cdot w_2) = (0.5 \\cdot 0.5) + (1.0 \\cdot 0.5) = 0.25 + 0.5 = 0.75\\)\n\nActivation (\\(h_1\\)): We apply the Sigmoid function (squashing the value).\n\n\\(h_1 = \\frac{1}{1 + e^{-z_1}} = \\frac{1}{1 + e^{-0.75}} \\approx 0.68\\)\n3. Output Layer Calculation:\n\nWeighted Sum (\\(z_2\\)):\n\n\\(z_2 = h_1 \\cdot w_3 = 0.68 \\cdot 1.0 = 0.68\\)\n\nFinal Prediction (\\(y_{pred}\\)):\n\n\\(y_{pred} = \\frac{1}{1 + e^{-z_2}} = \\frac{1}{1 + e^{-0.68}} \\approx 0.66\\)\n4. The Error (The Loss Function):\n\nTarget: 1.0\nActual: 0.66\nLoss (MSE): \\(L = \\frac{1}{2} (Target - Prediction)^2 = \\frac{1}{2} (1.0 - 0.66)^2 = \\frac{1}{2} (0.34)^2 = 0.058\\)\n\n\nThe Story: The factory manager looks at the product. ‚ÄúWe wanted a 1.0 quality alloy, but we got 0.66. This is a failure. Who is responsible?‚Äù\n\n\n\n\nStep 2: The Backward Pass (Assigning the Blame)\nNow we travel backward from the output to find out how to adjust the machines (weights).\n\nPhase A: Blaming the Output Weight (\\(w_3\\))\nWe need to calculate $ : ‚ÄúHow much did Weight 3 contribute to the error?‚Äù\nWe use the Chain Rule to break this into three simple links:\n\nHow did the Loss change as the Prediction changed?\n\n\\(\\frac{\\partial Loss}{\\partial y_{pred}} = -(Target - y_{pred}) = -(1.0 - 0.66) = -0.34\\) (Interpretation: We need the output to be higher.) 2. How did the Prediction change as the Input Sum (\\(z_2\\)) changed? (Sigmoid Derivative)\n\\(\\frac{\\partial y_{pred}}{\\partial z_2} = y_{pred} \\cdot (1 - y_{pred}) = 0.66 \\cdot (1 - 0.66) \\approx 0.2244\\)\n\nHow did the Input Sum (\\(z_2\\)) change as Weight 3 changed?\n\n\\(\\frac{\\partial z_2}{\\partial w_3} = h_1 = 0.68\\)\nThe Chain Rule Assembly:\n\\(Gradient_{w_3} = \\frac{\\partial Loss}{\\partial w_3} = \\frac{\\partial Loss}{\\partial y_{pred}} \\cdot \\frac{\\partial y_{pred}}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_3}\\)\n\\(= -0.34 \\cdot 0.2244 \\cdot 0.68 \\approx -0.0518\\)\n\nThe Story: ‚ÄúWeight 3, you are partly to blame. If we increase you, the error will go down.‚Äù\n\n\n\n\nPhase B: Passing the Blame Back (To \\(w_1\\) and \\(w_2\\))\nThis is the ‚ÄúBack‚Äù in Backpropagation. The output layer neuron yells at the hidden neuron: ‚ÄúI only gave the wrong answer because YOU gave me the wrong input!‚Äù\nWe need $ $ and $ $. The Chain Rule gets longer:\n\nThe ‚ÄúUpstream Gradient‚Äù (Blame from the Output): We already calculated the error sensitivity at the output sum: \\((-0.34 \\cdot 0.2244)=-0.075\\). Now we multiply it by the weight connecting them (\\(w_3\\)) to bring the error back to the hidden node.\n\nError at \\(h_1\\) = \\(-0.075 \\cdot w_3 = -0.075 \\cdot 1.0 = -0.075\\)\n\nHow did Hidden Output (\\(h_1\\)) change as Hidden Sum (\\(z_1\\)) changed? (Sigmoid Derivative again) \\(\\frac{\\partial h_1}{\\partial z_1} = h_1 \\cdot (1 - h_1) = 0.68 \\cdot (1 - 0.68) \\approx 0.2176\\)\nHow did Hidden Sum (\\(z_1\\)) change as Weight 1 (\\(w_1\\)) changed?\n\n\\(\\frac{\\partial z_1}{\\partial w_1} = x_1 = 0.5\\)\nThe Chain Rule Assembly:\n\\(Gradient_{w_1} = (Error_{h_1}) \\cdot (Sigmoid derivative) \\cdot (Input x_1)\\)\n\\(Gradient_{w_1} = -0.075 \\cdot 0.2176 \\cdot 0.5 \\approx -0.00816\\)\n\n\n\n\nStep 3: The Update (Fixing the Machines)\nNow that we know the gradients (the required direction of change), we apply the fix using a Learning Rate (\\(\\alpha\\)) of 0.1.\nNew Weight 3:\n\\(w_3^{new} = w_3 - (\\alpha \\cdot Gradient_{w_3}) = 1.0 - 0.1 \\cdot (-0.0518) = 1.0 + 0.00518 \\approx 1.00518\\)\n(We increase weight 3 slightly to boost the output).\nNew Weight 1:\n\\(w_1^{new} = w_1 - (\\alpha \\cdot Gradient_{w_1}) = 0.5 - 0.1 \\cdot (-0.00816) = 0.5 + 0.000816 \\approx 0.500816\\)\n(We increase weight 1 slightly).\n\n\nSummary of the Story\n\nForward: We passed data through to get a result.\nLoss: We realized the result was too low.\nChain Rule (Output): We calculated that increasing would help.\nChain Rule (Hidden): We passed that ‚Äúneed for increase‚Äù backward through to find out that increasing would also help.\nUpdate: We nudged all weights in the beneficial direction. The next time we run this input, the error will be slightly lower.",
    "crumbs": [
      "Home",
      "Backpropagation Storyteller"
    ]
  }
]